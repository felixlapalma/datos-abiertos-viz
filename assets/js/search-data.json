{
  
    
        "post0": {
            "title": "Mar Chiquita - Evolución Temporal de su Extension",
            "content": "A modo de referencia mostramos la extension de mar chiquita sobre la superficie de Córdoba (imagen Landsat5). . Para armar una imagen completa de Mar Chiquita es necesario 3 imágenes parciales de la misma. Es decir cada parte se obtiene de un parche azul de la imagen anterior. De las 3 imagenes parciales 2 pertenecen a la misma fecha (con una leve diferencia horaria) y la tercera suele tener una diferencia de unos 7 dias (anteriores o posteriores a las 2 primeras). En el fusionado de las imagenes aceptamos esta diferencia temporal y suponemos que no altera en forma considerable la fusión (en gral no se notan bordes discontinuos en margenes de la Mar). Entonces con estas 519 imagenes parciales armamos 168 imagenes completas de la Mar Chiquita. . Parches . Notemos el % de aporte de cada Path-Row (pisada de Landsat). El orden de la fusion de los parches tambien deben ser tenidos en cuenta (principalmente por nubes). Por ejemplo para el caso en cuestion: . Problemas en la Fusi&#243;n . Notemos que en la imagen superior (228-81/229-81/228-82) al fusionar conservamos la mayor cantidad de nubes (malo) pero si fusionamos en orden (229-81/228-81/228-82) solo conservamos una pequeña porcion sin alterar la calidad del fusionado. . Image Stats . Se trabajo con las imágenes (nubosidad &lt; 40%) provistas por los satelites (Path - Row: [229-81,228-81,228-82]) . Landsat 5 (LT05): periodo [1986, 2011] - 348 imagenes | Landsat 8 (LC08): periodo [2013, 2021] - 171 imagenes | . Unas 519 imágenes (~200Gb) usando rasterio,@dask_dev, @geopandas y @EoForge (entre otras). . Consideramos la nubosidad sobre la Mar y no la informada por los metadatos de la imagen satelital (puesto que estos lo hacen para toda la imagen) y puede prestarse a confusion (un % menor debido a la extension o informar nubosidad cuando en la region de la Mar no hay nubes.) . El proceso se realiza para el conjunto total de imagenes. Una vez realizado los cortes y las fusiones se procede a calcular un indice utilizando las bandas disponibles. . MNDWI . Particularmente consideramos el MNDWI: (green -MIR)/(green+MIR), una variacion del estandar NDWI: (green-NIR)/(green+NIR). MIR hace referencia a la banda infraroja media (B5 en Landsat5 por ejemplo) y NIR a la banda infraroja cercana (B4 en Landsat5). Este indice es particularmente util para resaltar cuerpos de agua por ejemplo. . Una vez calculado el indice se calcula un valor de referencia se procede a extraer la mascara (es decir aquellos valores que superan un umbral) y se la vectoriza (se genera el poligono en el sistema de coordenadas correspondientes y queda disponible para calcular, área, perimetro, etc). . Este proceso se repite para todo el set de imagenes, lo cual permite obtener la evolucion temporal del area ocupada por Mar Chiquita. . Evoluci&#243;n del Area . Sumamos una animación de la evolución de la extensión calculada de la Mar, donde incluimos como referencia (contorno gris) el área máxima ocupada en el periodo analizado. Si bien la animación contiene algunos polígonos que no son &quot;limpios&quot; (nubes,etc), la misma sirve para interpretar la evolución del área de la Mar y su comportamiento (hasta la fecha analizada). . &lt;IPython.core.display.Image object&gt; . Mostramos también una animación de la evolución de la Mar (Falso Color). La cantidad de imágenes es menor que la animación anterior (debido al tamaño de la imagen). . &lt;IPython.core.display.Image object&gt; . SAR - Optical . Para ir cerrando podríamos preguntarnos que pasa cuando tenemos (muchas) nubes? Eso lo podríamos responder con la siguiente figura (obtenida de @sentinel_hub), las imágenes (izquierda y derecha) tienen 1 día de diferencia. . Es decir, podríamos complementar la información de satélites con instrumentos ópticos (por ej, Landsat 8, Sentinel2) con satélites con Radar de Apertura Sintética - SAR (Sentinel1, SAOCOM,etc). . Para concluir marcamos que el sensado remoto es ideal para monitorear grandes extensiones (entre otras cosas), sumado al acceso libre de las imágenes satelitales y del sw de procesamiento, lo hacen un candidato adecuado para realizarlas en forma programática y automatizada. .",
            "url": "https://felixlapalma.github.io/datos-abiertos-viz/2021/07/16/Mar-Chiquita-Area-Monitoring.html",
            "relUrl": "/2021/07/16/Mar-Chiquita-Area-Monitoring.html",
            "date": " • Jul 16, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Incendios en Villa Albertina - Sentinel 2",
            "content": "Data . Para determinar las imagenes de la zona afectada usamos los vectores provisto por la plataforma geojson.io. . Las imagenes satelitales las descargamos desde la plataforma de sentinel, via la api sentinelsat. . Las imágenes corresponden a los dias . 20200815: _S2A_MSIL2A_20200815T141741_N0214_R010_T20JLM20200815T182929.zip | 20200817: _S2B_MSIL2A_20200817T141049_N0214_R110_T20JLM20200817T163953.zip | 20200820: _S2B_MSIL2A_20200820T141739_N0214_R010_T20JLM20200820T182855.zip | 20200822: _S2A_MSIL2A_20200822T141051_N0214_R110_T20JLM20200822T182240.zip | . # from http://geojson.io/#map=11/-30.5995/-64.2055 vector_file=&#39;data/villa_albertina.geojson&#39; # images from https://scihub.copernicus.eu using sentinelsat api zip_20200815=&#39;data/S2A_MSIL2A_20200815T141741_N0214_R010_T20JLM_20200815T182929.zip&#39; zip_20200817=&#39;data/S2B_MSIL2A_20200817T141049_N0214_R110_T20JLM_20200817T163953.zip&#39; # zip_20200820=&#39;data/S2B_MSIL2A_20200820T141739_N0214_R010_T20JLM_20200820T182855.zip&#39; zip_20200822=&#39;data/S2A_MSIL2A_20200822T141051_N0214_R110_T20JLM_20200822T182240.zip&#39; . Productos y temporales . #collapse class bands_etl(object): &quot;&quot;&quot; &quot;&quot;&quot; @staticmethod def get_ndi(band_1,band_2,weight=[1.0,1.0],dtype=rio.float32,nodata=-10000): ndi = (weight[0]*band_1.astype(float)-weight[1]*band_2.astype(float))/(band_1*weight[0]*+band_2*weight[1]) ndi_val=np.where((band_1*weight[0]*+band_2*weight[1])&gt;0,ndi,nodata) return ndi_val.astype(dtype) @staticmethod def get_band_paths(path_,pattern_=[&#39;*_10m.jp2&#39;]): &quot;&quot;&quot; &quot;&quot;&quot; names_bands={} all_names_bands={} for root, _, _ in os.walk(path_): for p in pattern_: ret=glob.glob(root+os.path.sep+p) if len(ret)&gt;0: j=0 for r in ret: full_path=os.path.join(root, r) name=os.path.basename(full_path) band=name.split(&#39;_&#39;)[-2] c={band:full_path} names_bands.update(c) all_names_bands.update({p+&#39;_&#39;+str(j):full_path}) j+=1 else: pass return names_bands,all_names_bands @staticmethod def basic_resampling(input_raster,output_raster,resampling_method=&#39;cubic&#39;,cell_size=20): &quot;&quot;&quot; :param input_raster: file to be resampled :param output_raster: file to be written &quot;&quot;&quot; warp_opts = [ &quot;-r&quot;, resampling_method, &quot;-tr&quot;, str(cell_size), str(cell_size), ] # gdal.UseExceptions() ds = gdal.Warp(output_raster, input_raster, options=warp_opts) # noqa del ds def set_band_names(self,band_dict): &quot;&quot;&quot; :param band_dict: dict with band names and paths &quot;&quot;&quot; self.band_names_=band_dict def get_band(self,b,open_flag): &quot;&quot;&quot; &quot;&quot;&quot; if open_flag: band_=rio.open(self.band_names_[b]) else: band_=b return band_ def set_mask_from_gpd(self,mask_gpd_geometry): &quot;&quot;&quot; &quot;&quot;&quot; self.mask_gpd_geom_=mask_gpd_geometry def get_clipping_params(self,band_init,mask_opts={&#39;crop&#39;:True},open_flag=True): &quot;&quot;&quot; &quot;&quot;&quot; band_=self.get_band(band_init,open_flag) out_image_init, out_transform_init = mask(band_, self.mask_gpd_geom_,**mask_opts) self.image_shape_0_=out_image_init[0].shape[0] self.image_shape_1_=out_image_init[0].shape[1] self.transform_=out_transform_init self.dtype_=out_image_init[0].dtype self.crs_=band_.crs def bands_clipped_to_tiff(self,bands_list,tiff_name_=&#39;bands.tiff&#39;,driver_=&#39;Gtiff&#39;,open_flag=True,scale_band=False): # Create an RGB image if scale_band: dtype_=rio.float32 else: dtype_=self.dtype_ with rio.open(tiff_name_,&#39;w&#39;,driver=driver_, width=self.image_shape_1_, height=self.image_shape_0_, count=len(bands_list),crs=self.crs_,transform=self.transform_, dtype=dtype_) as img: for i,b in enumerate(bands_list,start=1): band_=self.get_band(b,open_flag) out_image_init, out_transform_init = mask(band_, self.mask_gpd_geom_,crop=True) if scale_band: res=out_image_init[0]/out_image_init[0].max() img.write(res.astype(dtype_),i) else: img.write(out_image_init[0],i) # band_.close() out_image_init=None out_transform_init=None img.close() def ndi_to_tiff(self,band1_,band2_,weight=[1.0,1.0],tiff_name_=&#39;ndi.tiff&#39;,driver_=&#39;Gtiff&#39;,open_flag=True,nodata=-10000): # Create an NDVI image with rio.open(tiff_name_,&#39;w&#39;,driver=driver_, width=self.image_shape_0_, height=self.image_shape_1_, count=1,crs=self.crs_,transform=self.transform_, dtype=rio.float32,nodata=nodata) as img: band2_init=self.get_band(band2_,open_flag) band1_init=self.get_band(band1_,open_flag) band2, _ = mask(band2_init, self.mask_gpd_geom_,crop=True) band1, _ = mask(band1_init, self.mask_gpd_geom_,crop=True) band2_init.close() band1_init.close() img.write(self.get_ndi(band1,band2,weight,nodata=nodata)) img.close() def write_array_single( input_filename, output_filename, array, array_dtype=rio.uint8, nodata_=0, attribs_source_=&quot;profile&quot;, ): &quot;&quot;&quot; :param input_filename: input filename (vrt,tiff,etc) to be taken as src for profile :param output_filename: output filename :param array: numpy array to be written :param array_dtype: rasterio or numpy dtype :param nodata_: nodata to be written as integer (e.g.:-10000) :param attribs_source_: meta or profile &quot;&quot;&quot; with rio.open(input_filename) as src: attribs_ = getattr(src, attribs_source_) # update meta attribs_.update( dtype=array_dtype, count=1, driver=&quot;GTiff&quot;, nodata=nodata_, compresion=&quot;lzw&quot;, ) with rio.open(output_filename, &quot;w&quot;, **attribs_) as dst: dst.write(array.astype(array_dtype), 1) check_file = lambda path: os.remove(path) if os.path.isfile(path) else None . . Vector file proc . Incorporamos el archivo vectorial y lo referenciamos en el epsg correspondiente. . gpd_va=gpd.read_file(vector_file) gpd_va_proj = gpd_va.to_crs(epsg=32720) # gpd_vt=gpd.read_file(&#39;data/villa_del_totoral.geojson&#39;) gpd_vt_proj = gpd_vt.to_crs(epsg=32720) # cases_dict={} . Images proc . Procesamos las imagenes . # file=zip_20200817 date_=&#39;20200817&#39; dirtmp=tempfile.mkdtemp() with zipfile.ZipFile(file,&quot;r&quot;) as zip_ref: zip_ref.extractall(dirtmp) # # instanciamos el proc bp=bands_etl() # incluimos la capa vectorial bp.set_mask_from_gpd(gpd_va_proj.geometry) # Obtenemos los paths paths,_=bp.get_band_paths(dirtmp, pattern_=[&#39;*B0?_10m.jp2&#39;,&#39;*B1?_20m.jp2&#39;]) # # Debido a las diferencias en el pixel size de la bandas debemos resamplear resampled_bands={} for band in paths: case=&#39;_&#39;+date_+&#39;_Resampled&#39; name=os.path.join(products_tmp,band+case) resampled_bands.update({band:name}) bp.basic_resampling(paths[band],name) # shutil.rmtree(dirtmp) # seteamos las bandas bp.set_band_names(resampled_bands) # Generamos los parametros para el recorte bp.get_clipping_params(&#39;B02&#39;) # case=&#39;false_color_urban_&#39;+date_+&#39;.tiff&#39; tiff_name_=os.path.join(products,case) bp.bands_clipped_to_tiff([&#39;B12&#39;,&#39;B11&#39;,&#39;B04&#39;],tiff_name_=tiff_name_,scale_band=True) cases_dict.update({case:tiff_name_}) # case=&#39;false_color_urban_&#39;+date_+&#39;_NOTScaled.tiff&#39; tiff_name_=os.path.join(products,case) bp.bands_clipped_to_tiff([&#39;B12&#39;,&#39;B11&#39;,&#39;B04&#39;],tiff_name_=tiff_name_,scale_band=False) cases_dict.update({case:tiff_name_}) # case=&#39;rgb_&#39;+date_+&#39;.tiff&#39; tiff_name_=os.path.join(products,case) bp.bands_clipped_to_tiff([&#39;B04&#39;,&#39;B03&#39;,&#39;B02&#39;],tiff_name_=tiff_name_,scale_band=True) cases_dict.update({case:tiff_name_}) # case=&#39;rgb_&#39;+date_+&#39;_NOTSCaled.tiff&#39; tiff_name_=os.path.join(products,case) bp.bands_clipped_to_tiff([&#39;B04&#39;,&#39;B03&#39;,&#39;B02&#39;],tiff_name_=tiff_name_,scale_band=False) cases_dict.update({case:tiff_name_}) . Visualizamos . En falso color y rgb la zona afectada. A modo de referencia incluimos el ejido de villa del totoral (poligono blanco a izquierda). . Ahora vamos a estimar (en forma muy aproximada) el area afectada. Para ello nos valemos de la banda 11. Vemos que es la que mayor contraste parece tener . Analizamos los valores y efectuamos el &quot;thresholding&quot; con el fin de quedarnos con una imagen en blanco y negro. . #collapse file_path_threshold=os.path.join(products_tmp,&#39;thresholding_b11_20200817.tif&#39;) check_file(file_path_threshold) !gdal_calc.py --calc=&quot;A&gt;1400&quot; -A &#39;products/false_color_urban_20200817_NOTScaled.tiff&#39; --A_band=2 --outfile={file_path_threshold} --quiet . . Vemos que si bien remarcamos la mayoria de la zona, quedan algunas extras. Las intentamos remover e invertimos la imagen. . #collapse file_path_sieved=os.path.join(products_tmp,&#39;thresholding_b11_sieved_20200817.tif&#39;) check_file(file_path_sieved) !gdal_sieve.py {file_path_threshold} {file_path_sieved} -st 10 . . 0...10...20...30...40...50...60...70...80...90...100 - done. . &lt;AxesSubplot:&gt; . &lt;AxesSubplot:&gt; . Obtenemos el vector con la zona afectada via gdal-polygonize y visualizamos tanto el raster como el shapefile. . #collapse vector_fire_sieved=os.path.join(products_tmp,&#39;fire_shape_20200817.shp&#39;) !gdal_polygonize.py {raster_to_shape} {vector_fire_sieved} . . 0...10...20...30...40...50...60...70...80...90...100 - done. . 2020-08-15 . Realizamos un procesamiento similar (sin estimación de areas) para una fecha anterior a modo de contraste. . 2020-08-20 . Observamos la evolución al día 20/08. El procesamiento es similar, en este caso solo extendimos el shape original para enmarcar la zona. . Estimamos nuevamente el area afectada . &lt;AxesSubplot:&gt; . 2020-08-22 . Observamos la zona afectada al 22/08 . # file=zip_20200822 date_=&#39;20200822&#39; dirtmp=tempfile.mkdtemp() with zipfile.ZipFile(file,&quot;r&quot;) as zip_ref: zip_ref.extractall(dirtmp) # # instanciamos el proc bp=bands_etl() # incluimos la capa vectorial bp.set_mask_from_gpd(gpd_va_proj.geometry) # Obtenemos los paths paths,_=bp.get_band_paths(dirtmp, pattern_=[&#39;*B0?_10m.jp2&#39;,&#39;*B1?_20m.jp2&#39;]) # # Debido a las diferencias en el pixel size de la bandas debemos resamplear resampled_bands={} for band in paths: case=&#39;_&#39;+date_+&#39;_Resampled&#39; name=os.path.join(products_tmp,band+case) resampled_bands.update({band:name}) bp.basic_resampling(paths[band],name) # shutil.rmtree(dirtmp) # seteamos las bandas bp.set_band_names(resampled_bands) # Generamos los parametros para el recorte bp.get_clipping_params(&#39;B02&#39;) . case=&#39;false_color_urban_&#39;+date_+&#39;.tiff&#39; tiff_name_=os.path.join(products,case) bp.bands_clipped_to_tiff([&#39;B12&#39;,&#39;B11&#39;,&#39;B04&#39;],tiff_name_=tiff_name_,scale_band=True) cases_dict.update({case:tiff_name_}) # case=&#39;false_color_urban_&#39;+date_+&#39;_NOTScaled.tiff&#39; tiff_name_=os.path.join(products,case) bp.bands_clipped_to_tiff([&#39;B12&#39;,&#39;B11&#39;,&#39;B04&#39;],tiff_name_=tiff_name_,scale_band=False) cases_dict.update({case:tiff_name_}) # case=&#39;rgb_&#39;+date_+&#39;.tiff&#39; tiff_name_=os.path.join(products,case) bp.bands_clipped_to_tiff([&#39;B04&#39;,&#39;B03&#39;,&#39;B02&#39;],tiff_name_=tiff_name_,scale_band=True) cases_dict.update({case:tiff_name_}) # case=&#39;rgb_&#39;+date_+&#39;_NOTSCaled.tiff&#39; tiff_name_=os.path.join(products,case) bp.bands_clipped_to_tiff([&#39;B04&#39;,&#39;B03&#39;,&#39;B02&#39;],tiff_name_=tiff_name_,scale_band=False) cases_dict.update({case:tiff_name_}) . Observamos que todavia permanecen algunos focos activos. . Estimamos el area afectada . &lt;AxesSubplot:&gt; . Alternativa para el computo de area afectada . En este caso podemos estimar el area via el NBR (Normalized Burn Ratio). Computamos el indice (_bands_etl().ndi_totiff). Efectuamos el thresholding poligonizamos y generamos el area ( en este caso para el dia 22/08) . (355706.0, 386814.0, 6570194.0, 6620926.0) .",
            "url": "https://felixlapalma.github.io/datos-abiertos-viz/2020/08/22/Incendios_Villa_Albertina.html",
            "relUrl": "/2020/08/22/Incendios_Villa_Albertina.html",
            "date": " • Aug 22, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "COVID19- Argentina",
            "content": "Pre-Procesamiento . Unimos los DataFrames . Importamos los datos como DataFrames y los unimos. . Importando desde: https://github.com/felixlapalma/covid19-argentina-viz/blob/master/data/casos.xlsx?raw=true . provincia fecha confirmados muertes recuperados cumsum_confirmados cumsum_muertes cumsum_recuperados . 0 Argentina_Nacion | 2020-03-03 | 1 | 0 | 0 | 1 | 0 | 0 | . 1 Argentina_Nacion | 2020-03-04 | 0 | 0 | 0 | 1 | 0 | 0 | . 2 Argentina_Nacion | 2020-03-05 | 0 | 0 | 0 | 1 | 0 | 0 | . 3 Argentina_Nacion | 2020-03-06 | 1 | 0 | 0 | 2 | 0 | 0 | . 4 Argentina_Nacion | 2020-03-07 | 7 | 0 | 0 | 9 | 0 | 0 | . Procesamiento . Procesamos los datos y dejamos los mismos en el formato que seran utilizados en el reporte. . Visualizamos algunos: . provincia confirmados muertes recuperados Pconfirmados Pmuertes Precuperados confirmados (+) muertes (+) recuperados (+) Tasa Fatalidad . 0 Argentina_Nacion | 6034 | 305 | 1757 | 5611 | 293 | 1659 | 423 | 12 | 98 | 5.1 | . 1 Buenos Aires | 2112 | 128 | 238 | 2001 | 121 | 238 | 111 | 7 | 0 | 6.1 | . 2 CABA | 1961 | 96 | 433 | 1713 | 92 | 433 | 248 | 4 | 0 | 4.9 | . 3 Chaco | 459 | 19 | 207 | 418 | 19 | 194 | 41 | 0 | 13 | 4.1 | . 4 Córdoba | 333 | 21 | 167 | 322 | 21 | 160 | 11 | 0 | 7 | 6.3 | . 5 Rio Negro | 276 | 10 | 186 | 270 | 10 | 172 | 6 | 0 | 14 | 3.6 | . 6 Santa Fe | 244 | 3 | 190 | 244 | 3 | 190 | 0 | 0 | 0 | 1.2 | . 7 Tierra del Fuego | 148 | 0 | 86 | 145 | 0 | 86 | 3 | 0 | 0 | 0.0 | . 8 Neuquén | 111 | 5 | 31 | 110 | 5 | 31 | 1 | 0 | 0 | 4.5 | . 9 Mendoza | 86 | 9 | 43 | 86 | 9 | 43 | 0 | 0 | 0 | 10.5 | . Argentina Informe Diario Argentina Confirmados 6,034 (+423) Muertes 305 (+12) Recuperados 1,757 (+98) Actualizado 10 May, 2020 ( +cambio desde hace 2 dias) . CABA confirmados 1,961 (+248) muertes 96 (+4) Buenos Aires confirmados 2,112 (+111) muertes 128 (+7) Córdoba confirmados 333 (+11) muertes 21 (+0) En los últimos 2 dias, 423 nuevos casos de COVID19 se han reportado en Argentina. De los cuales 248 (59%) son de CABA. Buenos Aires ha reportado 111 (26%) casos nuevos en los ultimos 2 dias. . 10 50 100 1000 . Provincia Nuevos confirmados Total confirmados Muertes Fatalidad Recuperados . | Mar. 03 May. 10 | | (+NUEVOS) desde May, 08 | | | . Argentina_Nacion | | 6,034 | (+423) | 305 | (+12) | 5.1% | 1,757 | (+98) | . Buenos Aires | | 2,112 | (+111) | 128 | (+7) | 6.1% | 238 | (+0) | . CABA | | 1,961 | (+248) | 96 | (+4) | 4.9% | 433 | (+0) | . Chaco | | 459 | (+41) | 19 | (+0) | 4.1% | 207 | (+13) | . Córdoba | | 333 | (+11) | 21 | (+0) | 6.3% | 167 | (+7) | . Rio Negro | | 276 | (+6) | 10 | (+0) | 3.6% | 186 | (+14) | . Santa Fe | | 244 | (+0) | 3 | (+0) | 1.2% | 190 | (+0) | . Tierra del Fuego | | 148 | (+3) | 0 | (+0) | 0.0% | 86 | (+0) | . Neuquén | | 111 | (+1) | 5 | (+0) | 4.5% | 31 | (+0) | . Mendoza | | 86 | (+0) | 9 | (+0) | 10.5% | 43 | (+0) | . La Rioja | | 59 | (+0) | 7 | (+1) | 11.9% | 0 | (+0) | . Corrientes | | 54 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Santa Cruz | | 49 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Tucumán | | 41 | (+0) | 3 | (+0) | 7.3% | 0 | (+0) | . Entre Ríos | | 28 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Misiones | | 25 | (+0) | 1 | (+0) | 4.0% | 0 | (+0) | . Santiago del Estero | | 16 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . San Luis | | 11 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Jujuy | | 5 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . La Pampa | | 5 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Chubut | | 4 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Salta | | 4 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . San Juan | | 3 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Catamarca | | 0 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Formosa | | 0 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Curvas . Visualizamos algunas curvas y graficos relacionados al covid 19. En el grafico central podemos ver la evolucion de casos confirmados: . el radio indica la cantidad de casos confirmados en el dia (tooltip) | la selección de un dado dia activa el grafico de barra indicando la distribucion por provincia. | . Heatmap . Y observamos el heatmap correspondiente a los casos confirmados por dia .",
            "url": "https://felixlapalma.github.io/datos-abiertos-viz/2020/03/18/argentina_covid19_viz.html",
            "relUrl": "/2020/03/18/argentina_covid19_viz.html",
            "date": " • Mar 18, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Twitter Consume Reporter Argentina",
            "content": "Argentina x Provincia . En esta seccion mostramos la Demanda (MW) para una hora especifica de las distintas provincias de la Republica argentina. La jupyter notebook original de procesamiento se puede encontrar en src . Pre-Procesamiento . Las url de cammesa dependen de la provincia o sector a bajar, eso lo gestionamos via un diccionario . {&#39;La Rioja&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0129.xml&amp;header=datosDemandas&#39;}, &#39;Santiago del Estero&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0127.xml&amp;header=datosDemandas&#39;}, &#39;Tucuman&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0126.xml&amp;header=datosDemandas&#39;}, &#39;Salta&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0125.xml&amp;header=datosDemandas&#39;}, &#39;Jujuy&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0124.xml&amp;header=datosDemandas&#39;}, &#39;Catamarca&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0156.xml&amp;header=datosDemandas&#39;}, &#39;Cordoba&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0145.xml&amp;header=datosDemandas&#39;}, &#39;San Luis&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0146.xml&amp;header=datosDemandas&#39;}, &#39;Corrientes&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0118.xml&amp;header=datosDemandas&#39;}, &#39;Chaco&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0117.xml&amp;header=datosDemandas&#39;}, &#39;Formosa&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0116.xml&amp;header=datosDemandas&#39;}, &#39;Misiones&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0115.xml&amp;header=datosDemandas&#39;}, &#39;Santa Fe&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_2591.xml&amp;header=datosDemandas&#39;}, &#39;Entre Rios&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_2592.xml&amp;header=datosDemandas&#39;}, &#39;Mendoza&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0143.xml&amp;header=datosDemandas&#39;}, &#39;San Juan&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0144.xml&amp;header=datosDemandas&#39;}, &#39;La Pampa&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_2595.xml&amp;header=datosDemandas&#39;}, &#39;Neuquen&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_2596.xml&amp;header=datosDemandas&#39;}, &#39;Rio Negro&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_2590.xml&amp;header=datosDemandas&#39;}, &#39;Santa Cruz&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_2593.xml&amp;header=datosDemandas&#39;}, &#39;Chubut&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_2594.xml&amp;header=datosDemandas&#39;}, &#39;Buenos Aires&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDemandaArea5Min_0425.xml&amp;header=datosDemandasPreDes&#39;}, &#39;GBA&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDemandaArea5Min_0426.xml&amp;header=datosDemandasPreDes&#39;}, &#39;SADI&#39;: {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDemandaArea5Min_1002.xml&amp;header=datosDemandasPreDes&#39;}} . descargamos los archivos... . {&#39;La Rioja&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/La Rioja_provincia.csv&#39;}, &#39;Santiago del Estero&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Santiago del Estero_provincia.csv&#39;}, &#39;Tucuman&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Tucuman_provincia.csv&#39;}, &#39;Salta&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Salta_provincia.csv&#39;}, &#39;Jujuy&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Jujuy_provincia.csv&#39;}, &#39;Catamarca&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Catamarca_provincia.csv&#39;}, &#39;Cordoba&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Cordoba_provincia.csv&#39;}, &#39;San Luis&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/San Luis_provincia.csv&#39;}, &#39;Corrientes&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Corrientes_provincia.csv&#39;}, &#39;Chaco&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Chaco_provincia.csv&#39;}, &#39;Formosa&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Formosa_provincia.csv&#39;}, &#39;Misiones&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Misiones_provincia.csv&#39;}, &#39;Santa Fe&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Santa Fe_provincia.csv&#39;}, &#39;Entre Rios&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Entre Rios_provincia.csv&#39;}, &#39;Mendoza&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Mendoza_provincia.csv&#39;}, &#39;San Juan&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/San Juan_provincia.csv&#39;}, &#39;La Pampa&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/La Pampa_provincia.csv&#39;}, &#39;Neuquen&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Neuquen_provincia.csv&#39;}, &#39;Rio Negro&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Rio Negro_provincia.csv&#39;}, &#39;Santa Cruz&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Santa Cruz_provincia.csv&#39;}, &#39;Chubut&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Chubut_provincia.csv&#39;}, &#39;Buenos Aires&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/Buenos Aires_provincia.csv&#39;}, &#39;GBA&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/GBA_provincia.csv&#39;}, &#39;SADI&#39;: {&#39;provincia&#39;: &#39;tmp_mapa/SADI_provincia.csv&#39;}} . Dataframe procesado . Observamos el data frame procesado . FNA GNA NAM SAG IN1 geometry Consumo Consumo_Porc . 0 Provincia de Misiones | Provincia | Misiones | IGN | 54 | MULTIPOLYGON (((-54.10906 -25.53982, -54.11194... | 219.25 | 2.001848 | . 1 Provincia de San Luis | Provincia | San Luis | IGN | 74 | MULTIPOLYGON (((-67.05547 -31.85605, -67.05000... | 125.85 | 1.149065 | . 2 Provincia de San Juan | Provincia | San Juan | IGN | 70 | MULTIPOLYGON (((-67.32964 -32.35883, -67.32964... | 157.29 | 1.436126 | . 3 Provincia de Entre Ríos | Provincia | Entre Rios | IGN | 30 | MULTIPOLYGON (((-58.58138 -30.16010, -58.58102... | 329.82 | 3.011400 | . 4 Provincia de Santa Cruz | Provincia | Santa Cruz | IGN | 78 | MULTIPOLYGON (((-71.54709 -45.99975, -71.54573... | 190.62 | 1.740444 | . 5 Provincia de Río Negro | Provincia | Rio Negro | IGN | 62 | MULTIPOLYGON (((-64.76547 -40.78351, -64.76618... | 187.87 | 1.715335 | . 6 Provincia del Chubut | Provincia | Chubut | IGN | 26 | MULTIPOLYGON (((-71.85480 -43.49645, -71.85459... | 563.07 | 5.141074 | . 7 Provincia de Córdoba | Provincia | Cordoba | IGN | 14 | MULTIPOLYGON (((-63.87371 -29.62377, -63.86959... | 841.63 | 7.684448 | . 8 Provincia de Mendoza | Provincia | Mendoza | IGN | 50 | MULTIPOLYGON (((-69.12570 -32.00283, -69.12296... | 499.82 | 4.563574 | . 9 Provincia de La Rioja | Provincia | La Rioja | IGN | 46 | MULTIPOLYGON (((-68.52083 -27.81988, -68.52011... | 118.41 | 1.081135 | . 10 Provincia de Catamarca | Provincia | Catamarca | IGN | 10 | MULTIPOLYGON (((-67.97104 -25.22679, -67.86460... | 80.24 | 0.732626 | . 11 Provincia de La Pampa | Provincia | La Pampa | IGN | 42 | MULTIPOLYGON (((-64.46429 -35.00005, -64.44476... | 123.31 | 1.125874 | . 12 Provincia de Santiago del Estero | Provincia | Santiago del Estero | IGN | 86 | MULTIPOLYGON (((-62.04553 -25.65357, -62.03628... | 140.82 | 1.285748 | . 13 Provincia de Corrientes | Provincia | Corrientes | IGN | 18 | MULTIPOLYGON (((-57.97099 -27.27499, -57.96509... | 197.78 | 1.805818 | . 14 Provincia de Santa Fe | Provincia | Santa Fe | IGN | 82 | MULTIPOLYGON (((-60.21674 -27.99943, -59.81117... | 1012.54 | 9.244931 | . 15 Provincia de Tucumán | Provincia | Tucuman | IGN | 90 | MULTIPOLYGON (((-65.35915 -26.05944, -65.35868... | 259.26 | 2.367157 | . 16 Provincia del Neuquén | Provincia | Neuquen | IGN | 58 | MULTIPOLYGON (((-70.39361 -36.15157, -70.39325... | 291.95 | 2.665631 | . 17 Provincia de Salta | Provincia | Salta | IGN | 66 | MULTIPOLYGON (((-65.22229 -22.18944, -65.22212... | 162.31 | 1.481961 | . 18 Provincia del Chaco | Provincia | Chaco | IGN | 22 | MULTIPOLYGON (((-58.68415 -26.61219, -58.68341... | 208.14 | 1.900409 | . 19 Provincia de Formosa | Provincia | Formosa | IGN | 34 | MULTIPOLYGON (((-58.68043 -26.63314, -58.68176... | 97.27 | 0.888117 | . 20 Provincia de Jujuy | Provincia | Jujuy | IGN | 38 | MULTIPOLYGON (((-66.22124 -21.78140, -66.19414... | 52.24 | 0.476974 | . 21 Ciudad Autónoma de Buenos Aires | Ciudad Autónoma | Ciudad Autonoma de Buenos Aires | IGN | 02 | MULTIPOLYGON (((-58.45494 -34.53518, -58.45453... | 3471.44 | 31.695759 | . 22 Provincia de Buenos Aires | Provincia | Buenos Aires | IGN | 06 | MULTIPOLYGON (((-60.26319 -33.25989, -60.25421... | 1573.73 | 14.368840 | . y generamos el grafico correspondiente que sera utilizado en el tweet . Twitter Side . Cargamos la configuración y generamos el tweet correspondiente y mostramos un ejemplo (puede no corresponder a la imagen generada). . #collapse try: if local_config: ## .tweepy.json not available config_file = &#39;cfg/.tweepy.json&#39; with open(config_file) as fh: config = json.load(fh) else: # use sys.arg (## .tweepy.json not available) config={&#39;consumer_key&#39;:sys.argv[1], &#39;consumer_secret&#39;:sys.argv[2], &#39;access_token&#39;: sys.argv[3], &#39;access_token_secret&#39;:sys.argv[4]} auth = tweepy.OAuthHandler(config[&#39;consumer_key&#39;], config[&#39;consumer_secret&#39;]) auth.set_access_token(config[&#39;access_token&#39;], config[&#39;access_token_secret&#39;]) twitter = tweepy.API(auth) tweet =&#39;Demanda Provincias [MW] y % Total Pais&#39; image_path =figName # to attach the media file status = twitter.update_with_media(image_path, tweet) except: shutil.rmtree(tmp) sys.exit(&#39;Failed to TWEET&#39;) ## src: https://github.com/jupyter/notebook/issues/2790 class Tweet(object): def __init__(self, embed_str=None): self.embed_str = embed_str def _repr_html_(self): return self.embed_str . . Demanda Provincias [MW] y % Total Pais pic.twitter.com/3ZvRQTHfKS . &mdash; misc reporter (@ReporterMisc) April 13, 2020 Provincia . En esta seccion mostramos la Demanda (MW) para una serie de horas para una provincia en particular. La jupyter notebook original de procesamiento se puede encontrar en src . Pre-Procesamiento . Las url de cammesa dependen de la provincia o sector a bajar, eso lo gestionamos via un diccionario. Para el presente caso elegimos Cordoba. . Provincia-Sector: Cordoba . {&#39;provincia&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0145.xml&amp;header=datosDemandas&#39;, &#39;capital&#39;: &#39;https://aplic.cammesa.com/complemento-portal/descargar?type=csv&amp;value=ChtDem_0149.xml&amp;header=datosDemandas&#39;} . descargamos los archivos ... . {&#39;provincia&#39;: &#39;tmpCordoba/provincia.csv&#39;, &#39;capital&#39;: &#39;tmpCordoba/capital.csv&#39;} . Dataframe procesado . Observamos el data frame procesado . Dem Hoy_prov Dem Ayer_prov Dem Sem Ant_prov Dem Hoy_capital Dem Ayer_capital Dem Sem Ant_capital provincia_sin_capital . Fecha Hora . 2020-04-13 00:15:00 915.25 | 920.27 | 937.97 | 339.74 | 333.74 | 347.95 | 575.51 | . 2020-04-13 00:30:00 890.78 | 904.37 | 918.32 | 329.44 | 328.79 | 339.99 | 561.34 | . 2020-04-13 00:45:00 878.16 | 884.63 | 906.77 | 321.34 | 321.44 | 332.29 | 556.82 | . 2020-04-13 01:00:00 855.78 | 867.23 | 890.22 | 313.40 | 314.08 | 324.71 | 542.38 | . 2020-04-13 01:15:00 838.08 | 852.02 | 872.38 | 306.69 | 308.61 | 316.90 | 531.39 | . 2020-04-13 01:30:00 827.00 | 834.85 | 861.66 | 296.87 | 301.04 | 307.57 | 530.13 | . 2020-04-13 01:45:00 815.39 | 823.13 | 847.54 | 289.83 | 296.20 | 302.61 | 525.56 | . 2020-04-13 02:00:00 808.89 | 810.27 | 833.66 | 285.16 | 290.45 | 298.12 | 523.73 | . 2020-04-13 02:15:00 803.36 | 800.44 | 828.34 | 281.82 | 286.48 | 292.83 | 521.54 | . 2020-04-13 02:30:00 793.29 | 788.95 | 817.23 | 278.30 | 281.87 | 288.81 | 514.99 | . y generamos el grafico correspondiente que sera utilizado en el tweet . Twitter Side . Cargamos la configuración y generamos el tweet correspondiente y mostramos un ejemplo (puede no corresponder a la imagen generada). . #collapse try: if local_config: ## .tweepy.json not available config_file = &#39;cfg/.tweepy.json&#39; with open(config_file) as fh: config = json.load(fh) else: # use sys.arg (## .tweepy.json not available) config={&#39;consumer_key&#39;:sys.argv[1], &#39;consumer_secret&#39;:sys.argv[2], &#39;access_token&#39;: sys.argv[3], &#39;access_token_secret&#39;:sys.argv[4]} auth = tweepy.OAuthHandler(config[&#39;consumer_key&#39;], config[&#39;consumer_secret&#39;]) auth.set_access_token(config[&#39;access_token&#39;], config[&#39;access_token_secret&#39;]) twitter = tweepy.API(auth) tweet =tweet_text image_path =figName # to attach the media file status = twitter.update_with_media(image_path, tweet) except: shutil.rmtree(tmp) sys.exit(&#39;Failed to TWEET&#39;) ## src: https://github.com/jupyter/notebook/issues/2790 class Tweet(object): def __init__(self, embed_str=None): self.embed_str = embed_str def _repr_html_(self): return self.embed_str . . Cordoba - Demanda (MW) - 13-04-2020 07:30 - Total Provincia: 849.7 / Provincia sin Capital: 566.5 / Capital: 283.3 / pic.twitter.com/HW1vowvMZ2 . &mdash; misc reporter (@ReporterMisc) April 13, 2020",
            "url": "https://felixlapalma.github.io/datos-abiertos-viz/2019/07/23/consume_reporter.html",
            "relUrl": "/2019/07/23/consume_reporter.html",
            "date": " • Jul 23, 2019"
        }
        
    
  
    
        ,"post4": {
            "title": "Análisis sobre remises y taxis - Municipalidad de Córdoba",
            "content": ". Datos: Descarga . Al momento de realizar al análisis se descargan los archivos (la pagina indica actualizacion a demanda y debajo de esta indicacion menciona: Taxis habilitados en tiempo real. Estos recursos estan conectados a nuestra base de datos): lista-remises.csv y lista-taxi.csv disponibles en . https://gobiernoabierto.cordoba.gob.ar/transporte-publico/ | . . Pre-Procesamiento . Unimos los DataFrames . Cargamos el par de csvs y verificamos consistencia en las columnas para mergearlos. . Titular CUIT Patente Marca Modelo Año 0 OVEJEROS EDUARDO CESAR 12407195.0 HTF942 Chevrolet Corsa 2009 1 GONZALEZ EDMUNDO LUIS 17025493.0 OQK656 Chevrolet Classic 2015 2 NIEVA EDUARDO ALBERTO 22562430.0 NEX746 FIAT Siena 2013 3 FERREYRA PABLO SEBASTIAN 29449210.0 OAS345 Chevrolet Classic 2014 4 CORDOBA CARLOS RUBEN 17533044.0 PET958 Chevrolet Classic 2015 estado clase 0 Habilitado remis 1 Habilitado remis 2 Habilitado remis 3 Habilitado remis 4 Habilitado remis . . Pre-Procesamiento II . Antes de pasar al análisis, vamos a dejar ciertos comentarios en relacion a los datos. Tenemos (aparentes): . Faltantes | Errores en la carga | etc | . La intencion de esto es que la gente de gobiernoabierto@cordoba.gov.ar pueda revisar estos casos (y actualizar la data cuando corresponda). . Sumario e informaci&#243;n general . Observamos que la columna perteneciente a CUIT parece ser DNI (esto es consistente con lo observado en https://www.cordoba.gob.ar/ciudad/movilidad/buscador-taxis-remises/) . ## Veamos si tenemos nulos o similares pd_cat_raw.info(null_counts=True) . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 6776 entries, 0 to 6775 Data columns (total 8 columns): # Column Non-Null Count Dtype -- -- 0 Titular 6775 non-null object 1 CUIT 6775 non-null float64 2 Patente 6776 non-null object 3 Marca 6776 non-null object 4 Modelo 6776 non-null object 5 Año 6776 non-null int64 6 estado 6776 non-null object 7 clase 6776 non-null object dtypes: float64(1), int64(1), object(6) memory usage: 423.6+ KB . A partir del desglose anterior podemos observar que tenemos 6776 entradas (remises + taxis) y en los campos: . Titular: Tenemos un valor no asignado | CUIT: Tenemos un valor no asignado | . Titular NULL . Titular CUIT Patente Marca Modelo Año estado clase . 1374 NaN | 32281702.0 | SIN ASIGNAR | Chevrolet | Classic | 2010 | Habilitado | remis | . CUIT NULL . Titular CUIT Patente Marca Modelo Año estado clase . 1375 ALONSO FERRERO NESTOR ANDR | NaN | DWU780 | Chevrolet | Corsa | 2001 | Habilitado | remis | . CUIT Año . count 6.775000e+03 | 6776.000000 | . mean 7.898040e+11 | 2012.199675 | . std 6.500751e+13 | 24.603569 | . min 0.000000e+00 | 0.000000 | . 25% 1.224464e+07 | 2011.000000 | . 50% 1.753019e+07 | 2013.000000 | . 75% 2.410726e+07 | 2015.000000 | . max 5.350794e+15 | 2018.000000 | . Observamos que: . CUIT: valor minimo en 0 y valor maximo &gt;10^15 | Año: valor minimo en 0 | . Estas dos instancias deben ser un error en la carga. . CUIT 0 or &gt;10^15 . Titular CUIT Patente Marca Modelo Año estado clase . 2754 AMERICAN SERVICE | 0.000000e+00 | TEX398 | Ford | Galaxy | 1994 | Habilitado | remis | . 3871 ARCE AGOSTINA (ADM JUD GAITE ELIANA) | 5.350794e+15 | JDG592 | Chevrolet | Corsa | 2010 | Habilitado | taxi | . Año 0 . Titular CUIT Patente Marca Modelo Año estado clase . 4805 BERTA MARIA SOL | 28854703.0 | OGU039 | Chevrolet | Classic | 0 | Habilitado | taxi | . array([&#39;Chevrolet&#39;, &#39;FIAT&#39;, &#39;Fiar&#39;, &#39;Volkswagen&#39;, &#39;Renault&#39;, &#39;Peugeot&#39;, &#39;Toyota&#39;, &#39;Ford&#39;, &#39;Citroën&#39;, &#39;Suzuki&#39;, &#39;Chery&#39;, &#39;Desconocido&#39;, &#39;Mercedes Benz&#39;], dtype=object) . Tenemos un par de situaciones: . Fiar: pareceria ser FIAT | Desconocido: No queda claro, porque no figuraria esta informacion... | . Marca Fiar . Titular CUIT Patente Marca Modelo Año estado clase . 6 CABRERA CARLOS SALVADOR | 14409601.0 | AC556OM | Fiar | Cronos | 2018 | Habilitado | remis | . 45 GONZALEZ CRISTOBAL TIMOTEO | 7977228.0 | AC687WX | Fiar | Cronos | 2018 | Habilitado | remis | . 832 SALLITTO DANIEL ENRIQUE | 17154373.0 | AC795CI | Fiar | Cronos | 2018 | Habilitado | remis | . 959 RUIZ DIEGO HERNAN | 24471197.0 | AC886NY | Fiar | Cronos | 2018 | Habilitado | remis | . 1062 SPACHESI GUSTAVO GABRIEL | 23451313.0 | AC662TQ | Fiar | Cronos | 2018 | Habilitado | remis | . 1111 PEREZ SERGIO ALEJANDRO | 14894139.0 | AC783CZ | Fiar | Cronos | 2018 | Habilitado | remis | . 1457 CEJAS HUGO ALBERTO | 16741770.0 | AC710QF | Fiar | Cronos | 2018 | Habilitado | remis | . 1572 ROLDAN CARLOS OSCAR | 14707821.0 | AC323HJ | Fiar | Cronos | 2018 | Habilitado | remis | . 1833 LUDUEÑA CARLOS GUSTAVO | 20784098.0 | AC868UA | Fiar | Cronos | 2018 | Habilitado | remis | . 2048 MORALES CARLOS ALBERTO | 16293022.0 | AC776FS | Fiar | Cronos | 2018 | Habilitado | remis | . 2563 JAYMES NORMA NILDA | 11055713.0 | AC818CL | Fiar | Cronos | 2018 | Habilitado | remis | . 4038 ASIS BETSABE | 34840435.0 | AC706YK | Fiar | Cronos | 2018 | Habilitado | taxi | . 6301 RIERA NESTOR HUGO | 10444674.0 | AC606MM | Fiar | Cronos | 2018 | Habilitado | taxi | . Por el modelo queda claro que son FIAT (Quizas al momento de carga sea necesario algun esquema de seleccion y no de escritura...) . Marca Desconocido . Titular CUIT Patente Marca Modelo Año estado clase . 3475 MACHADO LUIS ALBERTO R. | 11561915.0 | NBH112 | Desconocido | - | 2013 | Habilitado | taxi | . Si se consulta por NBH112 @ https://www.rentascordoba.gob.ar/ resulta que: . FIAT - SEDAN 4 PUERTAS - SIENA FIRE 4P 1.4MPI 8V HP BZ | . En vez de estar completando quizas se podria hacer la consulta a la https://www.dnrpa.gov.ar/portal_dnrpa/ (y tener una replica de la info en la Municipalidad y otra en Rentas Provincial). . Reemplazo de Datos . En las instancias anteriores vamos a utilizar la informacion encontrada (para el caso &quot;Marca:Desconocida&quot;) o deducida (&quot;Marca:Fiar&quot;) . . An&#225;lisis . Moviles Habilitados . Existen instancias en las cuales se observan 2 titulares para una misma patente. Esto en si no constituye un problema, pero debemos descontarlos al mostrar los moviles habilitados. . Casos duplicados 17 /6776 . Text(0.5, 1.0, &#39;Moviles Habilitados&#39;) . Antiguedad del Parque Automotor . Segun la normativa, los vehiculos son validos a partir de 2006 (Ordenanza Nº 12624 Prorroga excepcionalmente, y por única vez, hasta el 30 de Junio de 2017 inclusive, la vida útil de los vehículos modelo 2006...). . array([2009, 2015, 2013, 2014, 2018, 2012, 2011, 2010, 2017, 2016, 2008, 2006, 2007, 2000, 2005, 2001, 2004, 1997, 2002, 1994, 1999, 0]) . Observamos el caso 0, lo vamos a descartar en esta instancia (segun observamos es un unico caso) . remis taxi . count 2810.0 | 3948.0 | . mean 2012.1 | 2012.7 | . std 2.9 | 2.7 | . min 1994.0 | 1999.0 | . 25% 2010.0 | 2011.0 | . 50% 2012.0 | 2013.0 | . 75% 2014.0 | 2015.0 | . max 2018.0 | 2018.0 | . Marcas mas utilizadas . Mostramos las marcas mas utilizadas para las diferentes clases (taxis y remises). En el mismo grafico indicamos la cantidad de cada Marca. . Adicionalmente mostramos el desglose por modelo para las 4 marcas mas utilizadas . Licencias Habilitadas en Taxis y Remis para una misma Patente . En el analisis se detecto que existen instancias en las cuales un mismo vehiculo consta tanto con las licencias de Taxi como de Remis. . clase remis taxi . Patente . AA782EA 1.0 | 1.0 | . AA814WC 1.0 | 1.0 | . KDM472 1.0 | 1.0 | . KWI327 1.0 | 1.0 | . POT175 1.0 | 1.0 | . Observamos que tenemos 5 instancias en las cuales tenemos licencias habilitantes tanto de taxi como remis para un mismo vehiculo (misma patente). Ahora utilizamos esta informacion para obtener el conjunto total. . Titular CUIT Marca Modelo Año estado clase Marca_upd . Patente . AA782EA MOLL NORA BEATRIZ | 12671032 | FIAT | Palio | 2016 | Habilitado | remis | FIAT | . AA782EA FAUDA HUGO WALTER | 16904435 | FIAT | Palio | 2016 | Habilitado | taxi | FIAT | . AA814WC ZITTA ALEJANDRO | 14155774 | Toyota | Etios | 2016 | Habilitado | remis | Toyota | . AA814WC CONTRERAS GUSTAVO ARIEL | 23089541 | Toyota | Etios | 2016 | Habilitado | taxi | Toyota | . KDM472 MERCAU MARIA CANDELARIA | 35054714 | Chevrolet | Classic | 2011 | Habilitado | remis | Chevrolet | . KDM472 GARAY ANA MARIA | 18374643 | Chevrolet | Classic | 2011 | Habilitado | taxi | Chevrolet | . KWI327 SAMPO JAVIER LUIS ESTEBAN | 28652026 | Chevrolet | Classic | 2012 | Habilitado | remis | Chevrolet | . KWI327 CARUSO CONCEPCION | 5008435 | Chevrolet | Corsa | 2012 | Habilitado | taxi | Chevrolet | . POT175 YABALE MARIO GONZALO | 26844562 | Chevrolet | Classic | 2016 | Habilitado | remis | Chevrolet | . POT175 MIRANDA JONATHAN ALEXIS | 33414262 | Chevrolet | Classic | 2016 | Habilitado | taxi | Chevrolet | . Licencias Habilitadas en Taxis y Remis para un mismo CUIT . Ahora vemos las licencias de taxi y remis habilitadas para un mismo CUIT en simultaneo. . clase remis taxi . CUIT . 6437852 1.0 | 1.0 | . 8651992 1.0 | 1.0 | . 11195523 1.0 | 2.0 | . 26490111 1.0 | 1.0 | . Observamos que tenemos dos situaciones: . Licencias cruzadas: La norma parece indicar que pueden tenerse un maximo de 2 licencias de un único tipo | Más licencias de las permitidas | . Titular Patente Marca Modelo Año estado clase Marca_upd . CUIT . 6437852 CUELLO AMADEO ANTONIO | OEB442 | Chevrolet | Classic | 2014 | Habilitado | remis | Chevrolet | . 6437852 CUELLO AMADEO ANTONIO | KYQ319 | FIAT | Siena | 2012 | Habilitado | taxi | FIAT | . 8651992 TULIAN ARMANDO RAMON | HUT122 | FIAT | Siena | 2009 | Habilitado | remis | FIAT | . 8651992 TULIAN ARMANDO RAMON | KUJ583 | FIAT | Siena | 2012 | Habilitado | taxi | FIAT | . 11195523 CATANI TERCILIO | OMY278 | FIAT | Siena | 2015 | Habilitado | remis | FIAT | . 11195523 CATANI TERCILIO | OYU673 | FIAT | Siena | 2015 | Habilitado | taxi | FIAT | . 11195523 CATANI TERCILIO | PQC231 | FIAT | Siena | 2016 | Habilitado | taxi | FIAT | . 26490111 PEREYRA MARCELO | LGL439 | FIAT | Siena | 2012 | Habilitado | remis | FIAT | . 26490111 PEREYRA MARCELO ALEJANDRO | AA398PY | FIAT | Siena | 2016 | Habilitado | taxi | FIAT | . Agentes Municipales y Licencias . Para ir cerrando analizamos la posibilidad de que Agentes municipales posean licencias (esto segun la normativa esta prohibido). Para ello utilizamos el archivo, encontramos que posee información de DNI de los agentes. Podemos entonces cruzar la informacion utilizando este dato (para un análisis mas detallado dirigirse a src) . FECHA PROGRAMA REPARTICION CGO DNI NOMBRES Titular CUIT Patente Marca Modelo Año estado clase Marca_upd _merge . 6983 2.0e+06 | 961000.0 | DIRECCION GENERAL DE CULTURA Y PATRIMONIOS | 412.0 | 5.4e+06 | CAMAÐO MIGUEL ANGEL | CAMAÐO MIGUEL ANGEL | 5.4e+06 | ITQ428 | Chevrolet | Classic | 2010.0 | Habilitado | taxi | Chevrolet | both | . 7548 2.0e+06 | 921013.0 | EDUCACION ESC. DE BO.COMERCIAL | 1302.0 | 2.7e+07 | MONIER MARIA SOLEDAD | MONIER MARIA SOLEDAD | 2.7e+07 | OXD476 | Chevrolet | Classic | 2015.0 | Habilitado | taxi | Chevrolet | both | . 10088 2.0e+06 | 733000.0 | DIRECCION DE OBRAS VIALES - CONSERV.INFRAEST. ... | 608.0 | 2.3e+07 | MORENO ADRIAN GUSTAVO | MORENO ADRIAN GUSTAVO | 2.3e+07 | JJT629 | Chevrolet | Corsa | 2010.0 | Habilitado | taxi | Chevrolet | both | . Vemos que obtenemos las tres situaciones. Una opción que pudo ocurrir es que las personas hallan tenido con anterioridad (al ingreso a la municipalidad) las licencias. Sin embargo la norma en su art. 48 inciso a) menciona en forma explícita que no pueden tener los agentes municipales licencias sin indicar que ocurre en casos en los cuales las licencias sean anteriores al ingreso de los mismos a planta. Quizas legislando esa parte o ampliando la información para marcar fecha de otorgamiento de licencias y antiguedad del agente se podrian entender mejor estos puntos. .",
            "url": "https://felixlapalma.github.io/datos-abiertos-viz/2019/01/24/taxis_remises_cba.html",
            "relUrl": "/2019/01/24/taxis_remises_cba.html",
            "date": " • Jan 24, 2019"
        }
        
    
  
    
        ,"post5": {
            "title": "Análisis sobre funcionarios públicos municipales - Municipalidad de Córdoba",
            "content": ". Datos: Descarga . Al momento de realizar al análisis los salarios de los funcionarios parecen haberse cargado desde abril del 2016 hasta octubre del 2018 (@ url) . . Pre-Procesamiento . Unimos los DataFrames . Unimos los data frames y nos fijamos faltantes. . csv sin data: data/sueldos-2016-09.csv - index: 5 @ lst_len csv sin data: data/sueldos-2017-12.csv - index: 20 @ lst_len csv sin data: data/sueldos-2018-08.csv - index: 28 @ lst_len . Observamos que tenemos tres csv sin datos (quizas algun defecto en la carga o similar). . Eliminamos la información no necesaria y generamos características extras. . Los que tenemos basicamente son datos indexados temporalmente. En una inspección preliminar se puede ver que existen algunos pagos desglosados (Mismo DOC, Mismo Mes, distintos Sueldos). Para este situación en casos de conteo, vamos a unificar la información sumando los ingresos para el mismo Mes. . Cada caso corresponde a una persona cuyo sueldo fue desdoblado. En general se observan en instancias unicas y sin recurrencia con la salvedad de un par de casos. . En lo que sigue vamos desechar los casos duplicados (pero sumar los ingresos correspondientemente). . . An&#225;lisis . G&#233;nero . Veamos como es la composición por genero (en forma temporal). . Absoluta . Vemos la contribución al total de funcionarios por género. . Relativa . Vemos la contribución porcentual al total de funcionarios por género. . Según se puede observar falta mucho para que la distribución sea igualitaria , aunque el acumulado indica que las incorporaciones de género F superan a las de género M (ver mas abajo). . Veamos los ingresos y egresos . Hacemos el merge de los data frames filtrados por mes y revisamos cuales se renuevan, cuales dejan de estar y cuales ingresan. . . Distribuci&#243;n de Salarios . Estad&#237;stico: Mediana . Veamos la distribución de Sueldo Bruto (utilizando la mediana) por género. . La misma muestra paridad en cuanto a género (esto parece consistente con un esquema de escalas salariales). . A partir de esta figura observamos que el Salario Bruto se incremento un cerca del 40% en un año y un 70% para el segundo año (tomando como base 04-2016). . Estad&#237;stico: Media . Veamos la distribución de Sueldo Bruto (utilizando la media) por género. . Evoluci&#243;n del Salario - Distribuci&#243;n . En lo que sigue observamos la distribución de los los salarios. . El último par de gráficas parecen indicar paridad en los sueldos brutos inclusive las distribuciones son similares (en la imagen mostramos para el mes 10-2018).Pero la cuestion parece estar en el balance nuevamente de los géneros. En el swarm-plot siguiente, observamos primero que la contribución por género en las distintas escalas es menor para &quot;F&quot; que para &quot;M&quot; y esto se pone de manifiesto en mayor manera al subir la escala salarial. . . Distribuci&#243;n (por DNI) de los Funcionarios . En lo siguiente analizamos la distribucion de los funcionarios por DNI. Con la salvedad de los extranjeros (DNI &gt;90.000.000), esto nos da una idea de la distribución de edades de los funcionarios. . Cada marca en el eje x, correponde a un rango entonces, por ejemplo, 5 millones implica el rango [5,10) millones, 10 millones implica [10,15) millones, etc Adicionalmente se pueden observar en la forma (#F,#M), la cantidad de casos por rango. . En general el genero &#39;F&#39; contribuye en todos los rangos (es decir existe un funcionario F equivalente al menos en Sueldo Bruto a uno o mas Funcionarios M), pero llama la atención el correspondiente a 20 millones en el cual esta equivalencia no parece mantenerse (existe una buena cantidad de casos M sin equivalencia para F). .",
            "url": "https://felixlapalma.github.io/datos-abiertos-viz/2018/12/30/sueldos_municipales_cba.html",
            "relUrl": "/2018/12/30/sueldos_municipales_cba.html",
            "date": " • Dec 30, 2018"
        }
        
    
  

  
  

  

  
  

  

  
  

  

  
  

  
  

}